{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Die Segmentation",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyP85bEf0z1+86d/2aIYrQLn",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bolinwong/DieSegmentation/blob/main/Die_Segmentation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wP0E0DOomOII"
      },
      "source": [
        "%tensorflow_version 1.x\r\n",
        "import tensorflow as tf\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R4u_tkQ_mVIz"
      },
      "source": [
        "!pip3 uninstall -y keras\r\n",
        "!pip3 install keras==2.1.0"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DN1kMiQFmaxF"
      },
      "source": [
        "!git clone https://github.com/matterport/Mask_RCNN\r\n",
        "%cd Mask_RCNN\r\n",
        "!pip3 install -r requirements.txt\r\n",
        "!python3 setup.py install"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YhtEZR4dmoWp"
      },
      "source": [
        "import os\r\n",
        "import sys\r\n",
        "import random\r\n",
        "import math\r\n",
        "import re\r\n",
        "import time\r\n",
        "import tensorflow as tf\r\n",
        "import numpy as np\r\n",
        "import skimage.io\r\n",
        "import cv2\r\n",
        "import matplotlib\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import xml.etree.ElementTree as ET\r\n",
        "import json\r\n",
        "\r\n",
        "# Root directory of the project\r\n",
        "ROOT_DIR = os.path.abspath(\"\")\r\n",
        "\r\n",
        "# Import Mask RCNN\r\n",
        "sys.path.append(ROOT_DIR)  # To find local version of the library\r\n",
        "from mrcnn.config import Config\r\n",
        "from mrcnn import utils\r\n",
        "import mrcnn.model as modellib\r\n",
        "from mrcnn import visualize\r\n",
        "from mrcnn.model import log\r\n",
        "\r\n",
        "%matplotlib inline \r\n",
        "\r\n",
        "# Directory to save logs and trained model\r\n",
        "MODEL_DIR = os.path.join(ROOT_DIR, \"logs\")\r\n",
        "\r\n",
        "# Local path to trained weights file\r\n",
        "COCO_MODEL_PATH = os.path.join(ROOT_DIR, \"mask_rcnn_coco.h5\")\r\n",
        "# Download COCO trained weights from Releases if needed\r\n",
        "if not os.path.exists(COCO_MODEL_PATH):\r\n",
        "    utils.download_trained_weights(COCO_MODEL_PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mlj_V-IWmwEQ"
      },
      "source": [
        "class DieConfig(Config):\r\n",
        "    # Give the configuration a recognizable name\r\n",
        "    NAME = \"die_detection\"\r\n",
        "    \r\n",
        "    NUM_CLASSES = 1+1\r\n",
        "\r\n",
        "    GPU_COUNT = 1\r\n",
        "    IMAGES_PER_GPU = 1\r\n",
        "\r\n",
        "config = DieConfig()\r\n",
        "config.display()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95pfBPLUGh2o"
      },
      "source": [
        "class DieDataset(utils.Dataset):\r\n",
        "    def load_dataset(self, dataset_dir):\r\n",
        "        self.add_class('dataset', 1, 'Die')\r\n",
        "      \r\n",
        "        \r\n",
        "        # find all images\r\n",
        "        for i, filename in enumerate(os.listdir(dataset_dir)):\r\n",
        "            if '.jpg' in filename:\r\n",
        "                self.add_image('dataset', \r\n",
        "                               image_id=i, \r\n",
        "                               path=os.path.join(dataset_dir, filename), \r\n",
        "                               annotation=os.path.join(dataset_dir, filename.replace('.jpg', '.json')))\r\n",
        "    \r\n",
        "    def extract_masks(self, filename):\r\n",
        "        json_file = os.path.join(filename)\r\n",
        "        with open(json_file) as f:\r\n",
        "            img_anns = json.load(f)\r\n",
        "            \r\n",
        "        masks = np.zeros([1200, 1600, len(img_anns['shapes'])], dtype='uint8')\r\n",
        "        classes = []\r\n",
        "        for i, anno in enumerate(img_anns['shapes']):\r\n",
        "            mask = np.zeros([1200, 1600], dtype=np.uint8)\r\n",
        "            cv2.fillPoly(mask, np.array([anno['points']], dtype=np.int32), 1)\r\n",
        "            masks[:, :, i] = mask\r\n",
        "            classes.append(self.class_names.index(anno['label']))\r\n",
        "        return masks, classes\r\n",
        " \r\n",
        "    # load the masks for an image\r\n",
        "    def load_mask(self, image_id):\r\n",
        "        # get details of image\r\n",
        "        info = self.image_info[image_id]\r\n",
        "        # define box file location\r\n",
        "        path = info['annotation']\r\n",
        "        # load XML\r\n",
        "        masks, classes = self.extract_masks(path)\r\n",
        "        return masks, np.asarray(classes, dtype='int32')\r\n",
        "    \r\n",
        "    def image_reference(self, image_id):\r\n",
        "        info = self.image_info[image_id]\r\n",
        "        return info['path']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PrD4vDvy0ggs"
      },
      "source": [
        "\r\n",
        "# Create training and validation set\r\n",
        "# train set\r\n",
        "dataset_train = DieDataset()\r\n",
        "dataset_train.load_dataset('/content/Mask_RCNN/samples/DieSegmentationData/Train')\r\n",
        "dataset_train.prepare()\r\n",
        "print('Train: %d' % len(dataset_train.image_ids))\r\n",
        " \r\n",
        "# test/val set\r\n",
        "dataset_val = DieDataset()\r\n",
        "dataset_val.load_dataset('/content/Mask_RCNN/samples/DieSegmentationData/Test')\r\n",
        "dataset_val.prepare()\r\n",
        "print('Test: %d' % len(dataset_val.image_ids))\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQl245ETEM_S"
      },
      "source": [
        "pip install labelme2coco "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCaWXdGy0yzV"
      },
      "source": [
        "# import package\r\n",
        "import labelme2coco\r\n",
        "\r\n",
        "# set directory that contains labelme annotations and image files\r\n",
        "labelme_folder = \"/content/Mask_RCNN/samples/DieSegmentationData/Test\"\r\n",
        "\r\n",
        "# set path for coco json to be saved\r\n",
        "save_json_path = \"/content/Mask_RCNN/samples/DieSegmentationData/Test.json\"\r\n",
        "\r\n",
        "# convert labelme annotations to coco\r\n",
        "labelme2coco.convert(labelme_folder, save_json_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sxWX43j51U4w"
      },
      "source": [
        "# import package\r\n",
        "import labelme2coco\r\n",
        "\r\n",
        "# set directory that contains labelme annotations and image files\r\n",
        "labelme_folder = \"/content/Mask_RCNN/samples/DieSegmentationData/Train\"\r\n",
        "\r\n",
        "# set path for coco json to be saved\r\n",
        "save_json_path = \"/content/Mask_RCNN/samples/DieSegmentationData/Train.json\"\r\n",
        "\r\n",
        "# convert labelme annotations to coco\r\n",
        "labelme2coco.convert(labelme_folder, save_json_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KTjwiMtX7FV1"
      },
      "source": [
        "# Load and display random samples\r\n",
        "image_ids = np.random.choice(dataset_train.image_ids, 10)\r\n",
        "for image_id in image_ids:\r\n",
        "    image = dataset_train.load_image(image_id)\r\n",
        "    mask, class_ids = dataset_train.load_mask(image_id)\r\n",
        "    visualize.display_top_masks(image, mask, class_ids, dataset_train.class_names)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-qJxTu7M7fQ_"
      },
      "source": [
        "# Create model in training mode\r\n",
        "model = modellib.MaskRCNN(mode=\"training\", config=config,\r\n",
        "                          model_dir=MODEL_DIR)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5bl4zDTKAC_"
      },
      "source": [
        "# Which weights to start with?\r\n",
        "init_with = \"coco\"  # imagenet, coco, or last\r\n",
        "\r\n",
        "if init_with == \"imagenet\":\r\n",
        "    model.load_weights(model.get_imagenet_weights(), by_name=True)\r\n",
        "elif init_with == \"coco\":\r\n",
        "    # Load weights trained on MS COCO, but skip layers that\r\n",
        "    # are different due to the different number of classes\r\n",
        "    # See README for instructions to download the COCO weights\r\n",
        "    model.load_weights(COCO_MODEL_PATH, by_name=True,\r\n",
        "                       exclude=[\"mrcnn_class_logits\", \"mrcnn_bbox_fc\", \r\n",
        "                                \"mrcnn_bbox\", \"mrcnn_mask\"])\r\n",
        "elif init_with == \"last\":\r\n",
        "    # Load the last model you trained and continue training\r\n",
        "    model.load_weights(model.find_last(), by_name=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o43PLZ219eTI"
      },
      "source": [
        "# Train the head branches\r\n",
        "# Passing layers=\"heads\" freezes all layers except the head\r\n",
        "# layers. You can also pass a regular expression to select\r\n",
        "# which layers to train by name pattern.\r\n",
        "model.train(dataset_train, dataset_val, \r\n",
        "            learning_rate=config.LEARNING_RATE, \r\n",
        "            epochs=1, \r\n",
        "            layers='heads')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WUuMRRY1voV"
      },
      "source": [
        "# Fine tune all layers\r\n",
        "# Passing layers=\"all\" trains all layers. You can also \r\n",
        "# pass a regular expression to select which layers to\r\n",
        "# train by name pattern.\r\n",
        "model.train(dataset_train, dataset_val, \r\n",
        "            learning_rate=config.LEARNING_RATE / 10,\r\n",
        "            epochs=2, \r\n",
        "            layers=\"all\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wp26HLKN3cM4"
      },
      "source": [
        "Detection"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2QEatNAa3dsr"
      },
      "source": [
        "\r\n",
        "class InferenceConfig(DieConfig):\r\n",
        "    GPU_COUNT = 1\r\n",
        "    IMAGES_PER_GPU = 1\r\n",
        "\r\n",
        "inference_config = InferenceConfig()\r\n",
        "\r\n",
        "# Recreate the model in inference mode\r\n",
        "model = modellib.MaskRCNN(mode=\"inference\", \r\n",
        "                          config=inference_config,\r\n",
        "                          model_dir=MODEL_DIR)\r\n",
        "\r\n",
        "# Get path to saved weights\r\n",
        "# Either set a specific path or find last trained weights\r\n",
        "# model_path = os.path.join(ROOT_DIR, \".h5 file name here\")\r\n",
        "model_path = model.find_last()\r\n",
        "\r\n",
        "# Load trained weights\r\n",
        "print(\"Loading weights from \", model_path)\r\n",
        "model.load_weights(model_path, by_name=True)\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s_GYQDKd3vGk"
      },
      "source": [
        "def get_ax(rows=1, cols=1, size=8):\r\n",
        "    \"\"\"Return a Matplotlib Axes array to be used in\r\n",
        "    all visualizations in the notebook. Provide a\r\n",
        "    central point to control graph sizes.\r\n",
        "    \r\n",
        "    Change the default size attribute to control the size\r\n",
        "    of rendered images\r\n",
        "    \"\"\"\r\n",
        "    _, ax = plt.subplots(rows, cols, figsize=(size*cols, size*rows))\r\n",
        "    return ax"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YsR8lZR33x9Y"
      },
      "source": [
        "# Test on a random image\r\n",
        "# Load and display random samples\r\n",
        "\r\n",
        "\r\n",
        "image_ids = np.random.choice(dataset_val.image_ids, 10)\r\n",
        "for image_id in image_ids:\r\n",
        " original_image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\r\n",
        "    modellib.load_image_gt(dataset_val, inference_config, \r\n",
        "                           image_id, use_mini_mask=False)\r\n",
        "\r\n",
        "log(\"original_image\", original_image)\r\n",
        "log(\"image_meta\", image_meta)\r\n",
        "log(\"gt_class_id\", gt_class_id)\r\n",
        "log(\"gt_bbox\", gt_bbox)\r\n",
        "log(\"gt_mask\", gt_mask)\r\n",
        "\r\n",
        "visualize.display_instances(original_image, gt_bbox, gt_mask, gt_class_id, \r\n",
        "                            dataset_train.class_names, figsize=(8, 8))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uvg_jxFl35ZG"
      },
      "source": [
        "results = model.detect([original_image], verbose=5)\r\n",
        "\r\n",
        "r = results[0]\r\n",
        "visualize.display_instances(original_image, r['rois'], r['masks'], r['class_ids'], \r\n",
        "                            dataset_val.class_names, r['scores'], ax=get_ax())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q_P_TILs3_ME"
      },
      "source": [
        "# Compute VOC-Style mAP @ IoU=0.5\r\n",
        "# Running on 10 images. Increase for better accuracy.\r\n",
        "image_ids = dataset_val.image_ids\r\n",
        "APs = []\r\n",
        "for image_id in image_ids:\r\n",
        "    # Load image and ground truth data\r\n",
        "    image, image_meta, gt_class_id, gt_bbox, gt_mask =\\\r\n",
        "        modellib.load_image_gt(dataset_val, inference_config,\r\n",
        "                               image_id, use_mini_mask=False)\r\n",
        "    molded_images = np.expand_dims(modellib.mold_image(image, inference_config), 0)\r\n",
        "    # Run object detection\r\n",
        "    results = model.detect([image], verbose=0)\r\n",
        "    r = results[0]\r\n",
        "    # Compute AP\r\n",
        "    AP, precisions, recalls, overlaps =\\\r\n",
        "        utils.compute_ap(gt_bbox, gt_class_id, gt_mask,\r\n",
        "                         r[\"rois\"], r[\"class_ids\"], r[\"scores\"], r['masks'])\r\n",
        "    APs.append(AP)\r\n",
        "    \r\n",
        "print(\"mAP: \", np.mean(APs))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}